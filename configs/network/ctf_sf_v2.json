{ "NetworkName" : "Example",
  "NetworkStructure":{
    "Feature Encoder":[
      { "layerType":"SeparableConv",
        "layerName":"SeparableConv",
        "layerInput":"input.state",
        "filters":16,
        "kernel_size":5,
        "strides":3,
        "padding":"valid",
        "depth_multiplier":2,
        "activation":"relu"},
      { "layerType":"Conv2D",
        "layerName":"Conv2D_1",
        "layerInput":"SeparableConv",
        "filters":32,
        "kernel_size":3,
        "strides":2,
        "activation":"relu"},
      { "layerType":"Flatten",
        "layerName":"Flatten",
        "layerInput":"Conv2D_1"},
      { "layerType":"Dense",
        "layerName":"Dense1",
        "layerInput":"Flatten",
        "outputSize":256,
        "activation":"relu"}
      ],
    "Phi":[
      { "layerType":"Dense",
        "layerName":"Phi_FC1",
        "layerInput":"Dense1",
        "outputSize":512,
        "activation":"relu"},
      { "layerType":"Dense",
        "layerName":"Phi_Out",
        "layerInput":"Phi_FC1",
        "outputSize":1024,
        "activation":"relu"}
      ],

    "Actor":[
      { "layerType":"Dense",
        "layerName":"Actor_FC",
        "layerInput":"Phi_Out",
        "outputSize":"actionSize",
        "activation":null},
      { "layerType":"SoftMax",
        "layerName":"Logits",
        "layerInput":"Actor_FC"},
      { "layerType":"LogSoftMax",
        "layerName":"LogLogits",
        "layerInput":"Actor_FC"}
    ],


    "Psi":[
      { "layerType":"Dense",
        "layerName":"Psi_FC1",
        "layerInput":"Phi_Out",
        "outputSize":256,
        "activation":"relu"},
      { "layerType":"Dense",
        "layerName":"Psi_FC2",
        "layerInput":"Psi_FC1",
        "outputSize":1024,
        "activation":"relu"}
    ],

    "Reward Prediction":[
      { "layerType":"Dense",
        "layerName":"Reward_out",
        "layerInput":"Phi_Out",
        "outputSize":1,
        "activation":"relu"}
    ],
    "Value":[
      { "layerType":"Dense",
        "layerName":"value_out",
        "ReuseLayer":"Reward_out",
        "layerInput":"Psi_FC2",
        "outputSize":1,
        "activation":"relu"}
    ],
    "State Prediction":[
      { "layerType":"Dense",
        "layerName":"state_pred_dense",
        "layerInput":"Phi_Out",
        "outputSize":256,
        "activation":"relu"},
      { "layerType":"Reshape",
        "layerName":"state_pred_reshape",
        "layerInput":"state_pred_dense",
        "target_shape":[4,4,16],
        "activation":"relu"},
      { "layerType":"Conv2DTranspose",
        "layerName":"state_pred_conv1",
        "layerInput":"state_pred_reshape",
        "filters":32,
        "kernel_size":3,
        "strides":3,
        "activation":"relu"},
      { "layerType":"Conv2DTranspose",
        "layerName":"state_pred_conv2",
        "layerInput":"state_pred_conv1",
        "filters":16,
        "kernel_size":5,
        "strides":3,
        "activation":"relu"},
      { "layerType":"Conv2DTranspose",
        "layerName":"state_pred_conv3",
        "layerInput":"state_pred_conv2",
        "filters":6,
        "kernel_size":2,
        "strides":1,
        "activation":"relu"},
      { "layerType":"Round",
        "layerName":"state_out",
        "layerInput":"state_pred_conv3"
      },
    ],

  },

  "NetworkOutputs":{
    "actor":"Logits",
    "log_logits":"LogLogits",
    "phi":"Phi_Out",
    "psi":"Psi_FC2",
    "reward_pred":"reward_out",
    "value":"value_out",
    "state_prediction":"state_out"
  },

  "NetworkVariableGroups":{
    "Actor":["Actor","Phi","Feature Encoder"],
    "Critic":["Psi","Phi","Feature Encoder"],
    "Reward":["Reward Prediction","Phi", "Feature Encoder"]
  }

}
