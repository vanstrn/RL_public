{ "RunName":"CTF_PPO_v3",
  "GPUCapacitty":0.95,
  "NetworkHPs":{"LR": 0.0002,
                "Optimizer":"Adam",
                "Gamma":0.98,
                "lambda":0.98,
                "EntropyBeta":0.005,
                "CriticBeta":0.5,
                "BatchSize":512,
                "MinibatchSize":32,
                "Epochs":2,
                "eps":0.2},

  "MaxEpisodes":50001,
  "MaxEpisodeSteps":150,
  "Epochs":1000,
  "SFSize":256,
  "LogFreq":100,
  "SaveFreq":5000,

  "EnvConfig":"CTF_1v1_1map.json",
  "NetworkConfig":"CTF_PPO_v2.json",
  "Method":"methods.PPO_v3.PPO"
  }
